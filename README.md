# U-net_Learnning
1.U-net网络的结构
2.学习了卷积（Con2d，ConvTransposed）。参数之前的关系。（kernel和padding，使图片不改变尺寸）
3.我模拟计算机手动粗略的走了一遍U-net的结构（包括B、通道数、图片高度H、图片宽度w）
5.把它内部每一步目的和为什么这么做搞明白了，下面是一些我的理解：


Q1:
如何理解通道？
通道有点类似于这块像素的特征。一块像素背后的通道越多说明这块像素暗含的语义就越多：比如我要识别一张图片中的动物。一块像素背后的通道可能就是1:是否毛发2:颜色3:是否眼睛4:…类似的特征。
Q2:
为什么第一次卷积之后不立刻进行Pooling？
Pooling会丢失信息，导致后期回摊出现误差。所以为了在获取足够丰富的语义后再丢失信息。不立刻进行pooling
Q3:
下采样是在丢失信息但是通道数反而变多？
它实际上是牺牲精确的位置信息换来这一大块像素背后更丰富的语义。用更丰富的语义去描述更大的范围。
Q4:
ConvTranspose2d做了什么？
第一步 将含有语义的像素穿插在空白像素中。扩大图片尺寸。 
第二步 讲含有语义的像素的通道回摊给周围的空白像素。
结果是，单一像素的通道变少，语义变得迷糊。
Q4：
cat函数不是简单的图片叠加，而是位置和语义通道的拼接。
cat函数把相同尺寸相同通道数的两张图片叠加在一起。其中一张通道含有位置信息。另一张通道含有语义信息。
Q5:
为什么到达谷底后反卷积、cat之后还要进行一次不改变图片尺寸的卷积（decoder）？
1.去毛刺。在反卷积之后，单一像素回摊给更多像素时会因为未知而出现一些错误。decoder用来缓冲这些错误。
2.圆润化。让位置和语义通道融合。
3.同时让通道数减半，修正由于cat而翻倍的通道数。
